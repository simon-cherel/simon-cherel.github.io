# Recreate Mini DALL-E
*Recreate Mini DALL-E : A Text-to-Image Generation Model, a machine learning model inspired by OpenAI's DALL-E.*

January 2022

The source code of the project is accessible here : [Colab notebook](https://colab.research.google.com/drive/1s1L8Myrl24q40SB87AP0Bp-iCDhhlzPP?usp=sharing). Be carefull, it takes a lot of time to compute and run.

![Mini Dall-e example](/project_6.jpg)


## Project Goals
Our goal with this project was to develop a model that could generate images based on text descriptions, similar to how DALL-E works. While our model may not have the same level of performance as the original DALL-E, it was developed by a team of novice machine learning enthusiasts using state-of-the-art tools and techniques.



Tools and Techniques
To build our model, we used the following tools and techniques:

VQ-GAN: A variant of GANs (Generative Adversarial Networks) for image generation
CLIP: A PyTorch-based text processing model developed by OpenAI
MNIST: A well-known dataset for image classification tasks, which we used to train our model
Results and Conclusion
Our model was able to generate images based on text descriptions, though it may not be as performant as the original DALL-E. However, we believe that our project serves as a valuable learning resource for others interested in exploring machine learning and image generation.

Thank you for visiting our page and we hope you enjoy learning about our project!